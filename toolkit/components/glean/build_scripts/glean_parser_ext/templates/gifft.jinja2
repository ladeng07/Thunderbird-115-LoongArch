// -*- mode: C++ -*-

/* This file is auto-generated by run_glean_parser.py.
   It is only for internal use by types in
   toolkit/components/glean/bindings/private */
{# The rendered source is autogenerated, but this
Jinja2 template is not. Please file bugs! #}

#include "mozilla/AppShutdown.h"
#include "mozilla/ClearOnShutdown.h"
#include "mozilla/glean/bindings/GleanJSMetricsLookup.h"
#include "mozilla/glean/bindings/jog/JOG.h"
#include "mozilla/Maybe.h"
#include "mozilla/Telemetry.h"
#include <tuple>
#include "mozilla/DataMutex.h"
{% if probe_type == "Scalar" %}
#include "nsClassHashtable.h"
#include "nsTHashMap.h"
{% endif %}
#include "nsIThread.h"
#include "nsThreadUtils.h"

#ifndef mozilla_glean_{{ probe_type }}GifftMap_h
#define mozilla_glean_{{ probe_type }}GifftMap_h

#define DYNAMIC_METRIC_BIT ({{runtime_metric_bit}})
#define GLEAN_METRIC_ID(id) ((id) & ((1ULL << {{id_bits}}) - 1))

namespace mozilla::glean {

using Telemetry::{{ probe_type }}ID;

{% if probe_type == "Histogram" %}

using MetricId = uint32_t; // Same type as in api/src/private/mod.rs
using TimerId = uint64_t; // Same as in TimingDistribution.h.
using MetricTimerTuple = std::tuple<MetricId, TimerId>;
class MetricTimerTupleHashKey : public PLDHashEntryHdr {
 public:
  using KeyType = const MetricTimerTuple&;
  using KeyTypePointer = const MetricTimerTuple*;

  explicit MetricTimerTupleHashKey(KeyTypePointer aKey) : mValue(*aKey) {}
  MetricTimerTupleHashKey(MetricTimerTupleHashKey&& aOther)
      : PLDHashEntryHdr(std::move(aOther)),
        mValue(std::move(aOther.mValue)) {}
  ~MetricTimerTupleHashKey() = default;

  KeyType GetKey() const { return mValue; }
  bool KeyEquals(KeyTypePointer aKey) const {
    return std::get<0>(*aKey) == std::get<0>(mValue) && std::get<1>(*aKey) == std::get<1>(mValue);
  }

  static KeyTypePointer KeyToPointer(KeyType aKey) { return &aKey; }
  static PLDHashNumber HashKey(KeyTypePointer aKey) {
    // Chosen because this is how nsIntegralHashKey does it.
    return HashGeneric(std::get<0>(*aKey), std::get<1>(*aKey));
  }
  enum { ALLOW_MEMMOVE = true };

 private:
  const MetricTimerTuple mValue;
};

typedef StaticDataMutex<UniquePtr<nsTHashMap<MetricTimerTupleHashKey, TimeStamp>>> TimerToStampMutex;
static inline Maybe<TimerToStampMutex::AutoLock> GetTimerIdToStartsLock() {
  static TimerToStampMutex sTimerIdToStarts("sTimerIdToStarts");
  auto lock = sTimerIdToStarts.Lock();
  // GIFFT will work up to the end of AppShutdownTelemetry.
  if (AppShutdown::IsInOrBeyond(ShutdownPhase::XPCOMWillShutdown)) {
    return Nothing();
  }
  if (!*lock) {
    *lock = MakeUnique<nsTHashMap<MetricTimerTupleHashKey, TimeStamp>>();
    RefPtr<nsIRunnable> cleanupFn = NS_NewRunnableFunction(__func__, [&] {
      if (AppShutdown::IsInOrBeyond(ShutdownPhase::XPCOMWillShutdown)) {
        auto lock = sTimerIdToStarts.Lock();
        *lock = nullptr;  // deletes, see UniquePtr.h
        return;
      }
      RunOnShutdown([&] {
        auto lock = sTimerIdToStarts.Lock();
        *lock = nullptr;  // deletes, see UniquePtr.h
      }, ShutdownPhase::XPCOMWillShutdown);
    });
    // Both getting the main thread and dispatching to it can fail.
    // In that event we leak. Grab a pointer so we have something to NS_RELEASE
    // in that case.
    nsIRunnable* temp = cleanupFn.get();
    nsCOMPtr<nsIThread> mainThread;
    if (NS_FAILED(NS_GetMainThread(getter_AddRefs(mainThread)))
      || NS_FAILED(mainThread->Dispatch(cleanupFn.forget(), nsIThread::DISPATCH_NORMAL))
    ) {
      // Failed to dispatch cleanup routine.
      // First, un-leak the runnable (but only if we actually attempted dispatch)
      if (!cleanupFn) {
        NS_RELEASE(temp);
      }
      // Next, cleanup immediately, and allow metrics to try again later.
      *lock = nullptr;
      return Nothing();
    }
  }
  return Some(std::move(lock));
}
{% elif probe_type == "Scalar" %}
typedef nsUint32HashKey SubmetricIdHashKey;
typedef nsTHashMap<SubmetricIdHashKey, std::tuple<ScalarID, nsString>>
    SubmetricToLabeledMirrorMapType;
typedef StaticDataMutex<UniquePtr<SubmetricToLabeledMirrorMapType>>
    SubmetricToMirrorMutex;
static inline Maybe<SubmetricToMirrorMutex::AutoLock> GetLabeledMirrorLock() {
  static SubmetricToMirrorMutex sLabeledMirrors("sLabeledMirrors");
  auto lock = sLabeledMirrors.Lock();
  // GIFFT will work up to the end of AppShutdownTelemetry.
  if (AppShutdown::IsInOrBeyond(ShutdownPhase::XPCOMWillShutdown)) {
    return Nothing();
  }
  if (!*lock) {
    *lock = MakeUnique<SubmetricToLabeledMirrorMapType>();
    RefPtr<nsIRunnable> cleanupFn = NS_NewRunnableFunction(__func__, [&] {
      if (AppShutdown::IsInOrBeyond(ShutdownPhase::XPCOMWillShutdown)) {
        auto lock = sLabeledMirrors.Lock();
        *lock = nullptr;  // deletes, see UniquePtr.h
        return;
      }
      RunOnShutdown([&] {
        auto lock = sLabeledMirrors.Lock();
        *lock = nullptr;  // deletes, see UniquePtr.h
      }, ShutdownPhase::XPCOMWillShutdown);
    });
    // Both getting the main thread and dispatching to it can fail.
    // In that event we leak. Grab a pointer so we have something to NS_RELEASE
    // in that case.
    nsIRunnable* temp = cleanupFn.get();
    nsCOMPtr<nsIThread> mainThread;
    if (NS_FAILED(NS_GetMainThread(getter_AddRefs(mainThread)))
      || NS_FAILED(mainThread->Dispatch(cleanupFn.forget(), nsIThread::DISPATCH_NORMAL))
    ) {
      // Failed to dispatch cleanup routine.
      // First, un-leak the runnable (but only if we actually attempted dispatch)
      if (!cleanupFn) {
        NS_RELEASE(temp);
      }
      // Next, cleanup immediately, and allow metrics to try again later.
      *lock = nullptr;
      return Nothing();
    }
  }
  return Some(std::move(lock));
}

namespace {
class ScalarIDHashKey : public PLDHashEntryHdr {
 public:
  typedef const ScalarID& KeyType;
  typedef const ScalarID* KeyTypePointer;

  explicit ScalarIDHashKey(KeyTypePointer aKey) : mValue(*aKey) {}
  ScalarIDHashKey(ScalarIDHashKey&& aOther)
      : PLDHashEntryHdr(std::move(aOther)), mValue(std::move(aOther.mValue)) {}
  ~ScalarIDHashKey() = default;

  KeyType GetKey() const { return mValue; }
  bool KeyEquals(KeyTypePointer aKey) const { return *aKey == mValue; }

  static KeyTypePointer KeyToPointer(KeyType aKey) { return &aKey; }
  static PLDHashNumber HashKey(KeyTypePointer aKey) {
    return static_cast<std::underlying_type<ScalarID>::type>(*aKey);
  }
  enum { ALLOW_MEMMOVE = true };

 private:
  const ScalarID mValue;
};
}  // namespace
typedef StaticDataMutex<UniquePtr<nsTHashMap<ScalarIDHashKey, TimeStamp>>> TimesToStartsMutex;
static inline Maybe<TimesToStartsMutex::AutoLock> GetTimesToStartsLock() {
  static TimesToStartsMutex sTimespanStarts("sTimespanStarts");
  auto lock = sTimespanStarts.Lock();
  // GIFFT will work up to the end of AppShutdownTelemetry.
  if (AppShutdown::IsInOrBeyond(ShutdownPhase::XPCOMWillShutdown)) {
    return Nothing();
  }
  if (!*lock) {
    *lock = MakeUnique<nsTHashMap<ScalarIDHashKey, TimeStamp>>();
    RefPtr<nsIRunnable> cleanupFn = NS_NewRunnableFunction(__func__, [&] {
      if (AppShutdown::IsInOrBeyond(ShutdownPhase::XPCOMWillShutdown)) {
        auto lock = sTimespanStarts.Lock();
        *lock = nullptr;  // deletes, see UniquePtr.h
        return;
      }
      RunOnShutdown([&] {
        auto lock = sTimespanStarts.Lock();
        *lock = nullptr;  // deletes, see UniquePtr.h
      }, ShutdownPhase::XPCOMWillShutdown);
    });
    // Both getting the main thread and dispatching to it can fail.
    // In that event we leak. Grab a pointer so we have something to NS_RELEASE
    // in that case.
    nsIRunnable* temp = cleanupFn.get();
    nsCOMPtr<nsIThread> mainThread;
    if (NS_FAILED(NS_GetMainThread(getter_AddRefs(mainThread)))
      || NS_FAILED(mainThread->Dispatch(cleanupFn.forget(), nsIThread::DISPATCH_NORMAL))
    ) {
      // Failed to dispatch cleanup routine.
      // First, un-leak the runnable (but only if we actually attempted dispatch)
      if (!cleanupFn) {
        NS_RELEASE(temp);
      }
      // Next, cleanup immediately, and allow metrics to try again later.
      *lock = nullptr;
      return Nothing();
    }
  }
  return Some(std::move(lock));
}

static inline bool IsSubmetricId(uint32_t aId) {
  // Submetrics have the 2^{{id_bits - id_signal_bits}} bit set.
  // (ID_BITS - ID_SIGNAL_BITS, keep it in sync with js.py).
  return (aId & (1 << {{id_bits - id_signal_bits}})) > 0;
}
{% endif %}

static{% if probe_type == "Event" or probe_type == "Scalar" %} inline{% endif %} Maybe<{{ probe_type }}ID> {{ probe_type }}IdForMetric(uint32_t aId) {
  switch(aId) {
{% for id, (mirror, metric_name) in ids_to_probes.items() %}
    case {{ id }}: { // {{ metric_name }}
      return Some({{ probe_type }}ID::{{ mirror }});
    }
{% endfor %}
    default: {
      if (MOZ_UNLIKELY(aId & (1 << DYNAMIC_METRIC_BIT))) {
        // Dynamic (runtime-registered) metric. Use its static (compiletime-
        // registered) metric's telemetry_mirror mapping.
        // ...if applicable.

        // Only JS can use dynamic (runtime-registered) metric ids.
        MOZ_ASSERT(NS_IsMainThread());

        auto metricName = JOG::GetMetricName(aId);
        // All of these should have names, but the storage only lasts until
        // XPCOMWillShutdown, so it might return `Nothing()`.
        if (metricName.isSome()) {
          auto maybeMetric = MetricByNameLookup(metricName.ref());
          if (maybeMetric.isSome()) {
            uint32_t staticId = GLEAN_METRIC_ID(maybeMetric.value());
            // Let's ensure we don't infinite loop, huh.
            MOZ_ASSERT(!(staticId & (1 << DYNAMIC_METRIC_BIT)));
            return {{ probe_type }}IdForMetric(staticId);
          }
        }
      }
      return Nothing();
    }
  }
}

}  // namespace mozilla::glean

#undef GLEAN_METRIC_ID
#undef DYNAMIC_METRIC_BIT

#endif  // mozilla_glean_{{ probe_type }}GifftMaps_h
